{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Understand Batch Size Dimensions </h1>",
   "id": "c470209b461cad57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T09:42:38.821733Z",
     "start_time": "2025-02-06T09:42:37.713070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import TrajectoryDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "# See Train Dimensions\n",
    "PATH = Path('.')\n",
    "window= 10\n",
    "batch_size = 5\n",
    "\n",
    "\n",
    "trainset = TrajectoryDataset(PATH / 'data/train.h5', window=window, flatten=True)\n",
    "validset = TrajectoryDataset(PATH / 'data/valid.h5', window=window, flatten=True)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1, persistent_workers=True)\n",
    "validloader = DataLoader(validset, batch_size=batch_size, shuffle=True, num_workers=1, persistent_workers=True)\n",
    "\n",
    "for i, (batch, _) in  enumerate(trainloader):\n",
    "    print(f\"{i} : {batch.shape}\")"
   ],
   "id": "731ef81e92244387",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : torch.Size([5, 40, 128, 128])\n",
      "1 : torch.Size([5, 40, 128, 128])\n",
      "2 : torch.Size([5, 40, 128, 128])\n",
      "3 : torch.Size([5, 40, 128, 128])\n",
      "4 : torch.Size([4, 40, 128, 128])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Understand UNET dimensions </h1>",
   "id": "264c92a289ed86a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T09:34:28.705677Z",
     "start_time": "2025-02-06T09:34:27.330837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nn import UNet\n",
    "\n",
    "in_channels = 4\n",
    "out_channels = 4\n",
    "mod_features = 66\n",
    "hidden_channels = [32, 64, 128]\n",
    "hidden_blocks = [2, 3, 5]\n",
    "spatial = 2\n",
    "\n",
    "# UNET Forward : x (B, C, H, W)\n",
    "unet = UNet(\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    mod_features=mod_features,\n",
    "    hidden_channels=hidden_channels,\n",
    "    hidden_blocks=hidden_blocks,\n",
    "    spatial=spatial,\n",
    ")\n",
    "\n",
    ")\n",
    "batch_size = 4\n",
    "x = torch.randn(batch_size, in_channels, 128, 128)\n",
    "\n",
    "\n",
    "y = torch.randn(batch_size, mod_features)\n",
    "\n",
    "\n",
    "output = unet(x, y)\n",
    "\n",
    "\n",
    "print(output.shape)"
   ],
   "id": "8820e74e17d9ec46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 128, 128])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Understand ScoreUNET dimensions </h1>",
   "id": "82db58fc5afe3d88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T09:43:45.905104Z",
     "start_time": "2025-02-06T09:43:44.806142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from score import ScoreUNet\n",
    "batch_size = 5\n",
    "MAR_channels = 4 # Example ['RF', 'T2m', 'U10m', MASK]\n",
    "window = 10\n",
    "y_dim = 128\n",
    "x_dim = 128\n",
    "\n",
    "CONFIG = { 'hidden_channels' : [32, 64, 128],  \\\n",
    "'hidden_blocks' : [2, 3, 5],  \\\n",
    "'spatial' : 2, \\\n",
    "'channels' : window*MAR_channels, \\\n",
    "'context' : 0,\\\n",
    "'embedding' : 64 }\n",
    "\n",
    "\n",
    "score_unet = ScoreUNet(**CONFIG)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn([batch_size, window*MAR_channels, y_dim, x_dim]) # because of flatten\n",
    "t = torch.rand(x.shape[0], dtype=x.dtype, device=x.device)\n",
    "\n",
    "print(f\"x:  {x.shape} , t: {t.shape}\")\n",
    "c = None\n",
    "\n",
    "# Forward pass through the ScoreUNet\n",
    "output = score_unet(x, t, c)\n",
    "\n",
    "# Print the output shape\n",
    "print(f\"Output Shape : {output.shape}\")  # Should be (batch_size, channels, x, y)"
   ],
   "id": "143cd78ab32f8ceb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([5, 40, 128, 128]) , t: torch.Size([5])\n",
      "Output Shape : torch.Size([5, 40, 128, 128])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Understand VPSDE dimensions </h1>",
   "id": "8a5fa1e72cbf1ead"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T09:50:21.256125Z",
     "start_time": "2025-02-06T09:50:20.183044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from score import ScoreUNet, VPSDE\n",
    "\n",
    "batch_size = 5\n",
    "MAR_channels = 4 # Example ['RF', 'T2m', 'U10m', MASK]\n",
    "window = 10\n",
    "y_dim = 128\n",
    "x_dim = 128\n",
    "\n",
    "CONFIG = { 'hidden_channels' : [32, 64, 128],  \\\n",
    "'hidden_blocks' : [2, 3, 5],  \\\n",
    "'spatial' : 2, \\\n",
    "'channels' : window*MAR_channels, \\\n",
    "'context' : 0,\\\n",
    "'embedding' : 64 }\n",
    "\n",
    "\n",
    "score_unet = ScoreUNet(**CONFIG)\n",
    "vpsde = VPSDE(score_unet, shape=(MAR_channels*window, y_dim, x_dim))\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn([batch_size, window*MAR_channels, y_dim, x_dim]) # because of flatten\n",
    "\n",
    "vpsde.loss(x)"
   ],
   "id": "3f7d791a7c0963db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3164, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Loop-Alike (Ensure Architecture design is well shaped)</h1>",
   "id": "1a20d23055a4cba6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T09:56:42.804419Z",
     "start_time": "2025-02-06T09:56:39.145096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from score import ScoreUNet, VPSDE\n",
    "\n",
    "# Common dimensions\n",
    "batch_size = 5\n",
    "MAR_channels = 4 # Example ['RF', 'T2m', 'U10m', MASK]\n",
    "window = 10\n",
    "y_dim = 128\n",
    "x_dim = 128\n",
    "\n",
    "# Define the network\n",
    "CONFIG = { 'hidden_channels' : [32, 64, 128],  \\\n",
    "'hidden_blocks' : [2, 3, 5],  \\\n",
    "'spatial' : 2, \\\n",
    "'channels' : window*MAR_channels, \\\n",
    "'context' : 0,\\\n",
    "'embedding' : 64 }\n",
    "\n",
    "# Denoiser and Scheduler\n",
    "score_unet = ScoreUNet(**CONFIG)\n",
    "vpsde = VPSDE(score_unet, shape=(MAR_channels*window, y_dim, x_dim))\n",
    "\n",
    "trainset = TrajectoryDataset(PATH / \"data/train.h5\", window=10, flatten=True)\n",
    "validset = TrajectoryDataset(PATH / \"data/valid.h5\", window=10, flatten=True)\n",
    "\n",
    "\n",
    "# Batch loop\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1, persistent_workers=True)\n",
    "validloader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=1, persistent_workers=True)\n",
    "for i, (batch, _) in enumerate(trainloader):\n",
    "        print(f\"{i} batch : {batch.shape}\")\n",
    "        loss = vpsde.loss(batch)"
   ],
   "id": "397047736ca7899a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batch : torch.Size([5, 40, 128, 128])\n",
      "1 batch : torch.Size([5, 40, 128, 128])\n",
      "2 batch : torch.Size([5, 40, 128, 128])\n",
      "3 batch : torch.Size([5, 40, 128, 128])\n",
      "4 batch : torch.Size([4, 40, 128, 128])\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "[TRAIN LOOP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 4, 3, 3], expected input[20, 10, 55, 66] to have 4 channels, but got 10 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 88\u001B[0m\n\u001B[1;32m     85\u001B[0m w \u001B[38;5;241m=\u001B[39m mask_batch\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# Convert mask to weight format\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;66;03m# **Compute VPSDE Loss**\u001B[39;00m\n\u001B[0;32m---> 88\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43msde\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     90\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/TFE/score.py:305\u001B[0m, in \u001B[0;36mVPSDE.loss\u001B[0;34m(self, x, c, w)\u001B[0m\n\u001B[1;32m    302\u001B[0m t \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    303\u001B[0m x, eps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(x, t, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 305\u001B[0m err \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m eps)\u001B[38;5;241m.\u001B[39msquare()\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m w \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m err\u001B[38;5;241m.\u001B[39mmean()\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/TFE/score.py:144\u001B[0m, in \u001B[0;36mMCScoreWrapper.forward\u001B[0;34m(self, x, t, c)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    140\u001B[0m     x: Tensor,  \u001B[38;5;66;03m# (B, L, C, H, W)\u001B[39;00m\n\u001B[1;32m    141\u001B[0m     t: Tensor,  \u001B[38;5;66;03m# ()\u001B[39;00m\n\u001B[1;32m    142\u001B[0m     c: Tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,  \u001B[38;5;66;03m# TODO\u001B[39;00m\n\u001B[1;32m    143\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/TFE/score.py:127\u001B[0m, in \u001B[0;36mScoreUNet.forward\u001B[0;34m(self, x, t, c)\u001B[0m\n\u001B[1;32m    124\u001B[0m t \u001B[38;5;241m=\u001B[39m t\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    125\u001B[0m t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(t)\n\u001B[0;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(x\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/TFE/nn.py:216\u001B[0m, in \u001B[0;36mUNet.forward\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m    213\u001B[0m memory \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m head, blocks \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdescent):\n\u001B[0;32m--> 216\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mhead\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m blocks:\n\u001B[1;32m    219\u001B[0m         x \u001B[38;5;241m=\u001B[39m block(x, y)\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/conv.py:554\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 554\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/deep_learning/lib/python3.9/site-packages/torch/nn/modules/conv.py:549\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\n\u001B[1;32m    539\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[1;32m    540\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    547\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[1;32m    548\u001B[0m     )\n\u001B[0;32m--> 549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=1, weight of size [64, 4, 3, 3], expected input[20, 10, 55, 66] to have 4 channels, but got 10 channels instead"
     ]
    }
   ],
   "execution_count": 13,
   "source": [
    "import os\n",
    "import h5py\n",
    "import math\n",
    "import torch\n",
    "#import wandb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "from pathlib import Path\n",
    "from utils import TrajectoryDataset\n",
    "from score import ScoreUNet, MCScoreWrapper, VPSDE\n",
    "from score import VPSDE\n",
    "\n",
    "PATH = Path('.')\n",
    "\n",
    "with h5py.File(PATH / \"data/mask.h5\", \"r\") as f:\n",
    "    mask = torch.tensor(f[\"dataset\"][:], dtype=torch.float32).unsqueeze(0)  # Shape\n",
    "\n",
    "def masked_vpsde_loss(sde, x, mask):\n",
    "    w = mask.expand_as(x)\n",
    "    return sde.loss(x, w=w)\n",
    "\n",
    "CONFIG = {\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"scheduler\": \"linear\",  # Can be \"cosine\" or \"exponential\"\n",
    "    \"embedding\": 32,\n",
    "    \"hidden_channels\": (64,),\n",
    "    \"hidden_blocks\": (3,),\n",
    "    \"activation\": \"SiLU\",\n",
    "}\n",
    "\n",
    "trainset = TrajectoryDataset(PATH / \"data/train.h5\", window=10)\n",
    "validset = TrajectoryDataset(PATH / \"data/valid.h5\", window=10)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=1, persistent_workers=True)\n",
    "validloader = DataLoader(validset, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=1, persistent_workers=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "score_model = MCScoreWrapper(\n",
    "    ScoreUNet(\n",
    "        channels=4,\n",
    "        embedding=CONFIG[\"embedding\"],\n",
    "        hidden_channels=CONFIG[\"hidden_channels\"],\n",
    "        hidden_blocks=CONFIG[\"hidden_blocks\"],\n",
    "        activation=nn.SiLU,\n",
    "    )\n",
    ").to(device)\n",
    "\n",
    "sde = VPSDE(score_model, shape=(10, 4, 55, 66)).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(sde.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "\n",
    "# Define Learning Rate Scheduler\n",
    "if CONFIG[\"scheduler\"] == \"linear\":\n",
    "    lr_lambda = lambda t: 1 - (t / CONFIG[\"epochs\"])\n",
    "elif CONFIG[\"scheduler\"] == \"cosine\":\n",
    "    lr_lambda = lambda t: (1 + math.cos(math.pi * t / CONFIG[\"epochs\"])) / 2\n",
    "elif CONFIG[\"scheduler\"] == \"exponential\":\n",
    "    lr_lambda = lambda t: math.exp(-7 * (t / CONFIG[\"epochs\"]) ** 2)\n",
    "else:\n",
    "    raise ValueError(\"Invalid scheduler type\")\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "for epoch in (bar := trange(CONFIG[\"epochs\"], ncols=88)):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "\n",
    "    ## Train\n",
    "    sde.train()\n",
    "    print('-------')\n",
    "    print('[TRAIN LOOP]')\n",
    "    for i, (batch, _) in enumerate(trainloader):\n",
    "        print(f\"{i}\")\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # **Apply Mask**\n",
    "        mask_batch = mask.to(device).expand_as(batch)  # Expand mask to match batch size\n",
    "        w = mask_batch.float()  # Convert mask to weight format\n",
    "\n",
    "        # **Compute VPSDE Loss**\n",
    "        loss = sde.loss(batch, w=w)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_train.append(loss.detach())\n",
    "    print('[\\TRAIN LOOP]')\n",
    "    print('-------')\n",
    "    ## Validation\n",
    "    sde.eval()\n",
    "    with torch.no_grad():\n",
    "        print('-------')\n",
    "        print('[VALID LOOP]')\n",
    "        for batch, _ in validloader:\n",
    "            batch = batch.to(device)\n",
    "            mask_batch = mask.to(device).expand_as(batch)\n",
    "            w = mask_batch.float()\n",
    "\n",
    "            loss = sde.loss(batch, w=w)\n",
    "            losses_valid.append(loss)\n",
    "        print('-------')\n",
    "        print('[VALID LOOP]')\n",
    "    ## Compute Loss Stats\n",
    "    loss_train = torch.stack(losses_train).mean().item()\n",
    "    loss_valid = torch.stack(losses_valid).mean().item()\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    ## Step Scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save model periodically\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(sde.state_dict(), PATH / f\"checkpoints/model_epoch{epoch+1}.pth\")"
   ],
   "id": "148a48cdf5035725"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

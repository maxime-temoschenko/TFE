{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5354eb1b-2db2-4923-9189-8b00f18fbb96",
   "metadata": {},
   "source": [
    "<h1><strong>Weather Prediction Experiment</strong></h1>\n",
    "<p>In this experiment, we will use the first time step to predict the entire trajectory.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6defd60-9201-4092-9cd7-804eb48f0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import h5py\n",
    "import preprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import SequenceDataset, plot_sample\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from pathlib import Path\n",
    "# Import the necessary classes\n",
    "from score import ScoreUNet\n",
    "from score import VPSDE\n",
    "from score import GaussianScore\n",
    "import importlib\n",
    "import score\n",
    "importlib.reload(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9eb46-4743-4b51-9890-f75819fe3361",
   "metadata": {},
   "source": [
    "<h2>Load Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc0cb6-ba64-472d-bc94-edf50d7630c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"slurm/checkpoints/attention_config_spatial_T2m_U10m_2000_2014/attention_config_spatial_T2m_U10m_2000_2014_310.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9e89a-a2a2-4f9a-a0c5-fdea9ffcf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import score\n",
    "importlib.reload(score)\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "PATH_DATA = Path('./data/processed')\n",
    "# Load mask\n",
    "with h5py.File(PATH_DATA / \"mask.h5\", \"r\") as f:\n",
    "    mask = torch.tensor(f[\"dataset\"][:], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    mask_cpu = mask.detach().clone().cpu()\n",
    "if torch.isnan(mask).any():\n",
    "    raise ValueError(\"Mask contains NaN values!\")\n",
    "window = 12\n",
    "# Load dataset to get dimensions\n",
    "testset = SequenceDataset(PATH_DATA / \"test.h5\", window=window, flatten=True)\n",
    "channels, y_dim, x_dim = testset[0][0].shape\n",
    "print(f\"Channels : {channels}\")\n",
    "\n",
    "TRAIN_CONFIG = {\n",
    "    \"epochs\": 10000,\n",
    "    \"batch_size\": 5,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"scheduler\": \"cosine\",\n",
    "    \"embedding\": 64,\n",
    "    \"activation\": \"SiLU\",\n",
    "    \"eta\": 5e-3,\n",
    "}\n",
    "MODEL_CONFIG = { 'hidden_channels' : [64, 128,128,256],\n",
    "'attention_levels' : [2],\n",
    "'hidden_blocks' : [2,3,3,3],\n",
    "'spatial' : 2,\n",
    "'channels' : channels,\n",
    "'context' : 4,\n",
    "'embedding' : 64 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13652a4c-75cb-4bb1-ad62-67248a83460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = TRAIN_CONFIG['batch_size']\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=1, persistent_workers=True)\n",
    "# Initialize ScoreUNet and VPSDE\n",
    "score_unet = ScoreUNet(**MODEL_CONFIG).to(device)\n",
    "vpsde = VPSDE(score_unet, shape=(channels, y_dim, x_dim), eta = TRAIN_CONFIG[\"eta\"]).to(device)\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "vpsde.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Model restored from {checkpoint_path}, trained until epoch {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee8501c-e63c-4f03-b599-feae0157ea29",
   "metadata": {},
   "source": [
    "<h2>Define First Time Step Operator A(x)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b272acb1-014c-436c-be35-4ae16ed62bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_timestep(batch, mask):\n",
    "    \"\"\"Extract only the first timestep from the batch and replicate it across all timesteps.\"\"\"\n",
    "    if batch.ndim == 4:\n",
    "        batch = batch.unsqueeze(0)\n",
    "    S, B, C, H, W = batch.shape\n",
    "    num_variables = 2  # T2m and U10m\n",
    "    window = C // num_variables\n",
    "    batch_reshaped = batch.view(S, B, window, num_variables, H, W)\n",
    "    first_step = batch_reshaped[:, :, 0, :, :, :]\n",
    "    expanded = first_step.unsqueeze(2).expand(-1, -1, window, -1, -1, -1)\n",
    "    return expanded.reshape(S, B, C, H, W) * mask\n",
    "\n",
    "def A(x):\n",
    "    return first_timestep(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba8d35-cd22-4bf3-99f0-ee85633c3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch, dic = next(iter(testloader))\n",
    "batch = batch.to(device)\n",
    "first_step_data = A(batch)\n",
    "\n",
    "new_tensor = torch.stack((batch.cpu(), first_step_data.squeeze(0).cpu()), dim=1).flatten(0,1).cpu()\n",
    "path_unnorm = PATH_DATA/ \"train.h5\"\n",
    "info  = {'var_index': ['T2m', 'U10m'], 'channels' : 2, 'window' : 12}\n",
    "fig = plot_sample(new_tensor, info, mask_cpu, samples=4, step=3, unnormalize=True, path_unnorm=path_unnorm)\n",
    "plt.suptitle(\"Original Data vs First Timestep Only\", fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc92c2-3a1d-45b4-9f29-5f05d7280ea5",
   "metadata": {},
   "source": [
    "<h2>Prediction Experiment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461c0cf-0131-4418-83ea-84e6dbba0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star, c_star = next(iter(testloader))\n",
    "x_star = x_star.to(device)\n",
    "c_star = c_star['context'].to(device)\n",
    "\n",
    "\n",
    "y_star = torch.normal(A(x_star), 1e-2)*mask  \n",
    "\n",
    "info  = {'var_index': ['T2m', 'U10m'], 'channels' : 2, 'window' : 12}\n",
    "comparison = torch.stack((x_star.cpu(), y_star.squeeze(0).cpu()), dim=1).flatten(0,1).cpu()\n",
    "fig = plot_sample(comparison, info, mask_cpu, samples=2, step=2, unnormalize=True, path_unnorm=path_unnorm)\n",
    "plt.suptitle(\"Ground Truth vs First Timestep Input\", fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb39793-2da3-4a82-bb05-9fd5894039f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import score\n",
    "importlib.reload(score)\n",
    "x_star, c_star = next(iter(testloader))\n",
    "x_star, c_star = x_star[0].unsqueeze(0), c_star['context'][0].unsqueeze(0)\n",
    "print(x_star.shape, c_star.shape)\n",
    "x_star = x_star.to(device)\n",
    "c_star = c_star.to(device)\n",
    "y_star = torch.normal(A(x_star), 1e-2)*mask  \n",
    "print(y_star.shape)\n",
    "sde = VPSDE(score.DPSGaussianScore(y_star, mask, A=A, sde=vpsde, zeta=15.0), shape=x_star.shape).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa39de-4f35-4ccc-b6d7-58913eb64962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 3\n",
    "x_preds = sde.sample(mask, shape=(num_samples,), c=c_star, steps=512, corrections=8, tau=0.5).cpu()\n",
    "all_tensors = [x_star.detach().cpu(), y_star.squeeze(0).detach().cpu()] + [x_preds[i] for i in range(num_samples)]\n",
    "new_tensor = torch.stack(all_tensors, dim=1).flatten(0,1).cpu()\n",
    "\n",
    "path_unnorm = PATH_DATA/ \"train.h5\"\n",
    "info  = {'var_index': ['T2m', 'U10m'], 'channels' : 2, 'window' : 12}\n",
    "fig = plot_sample(new_tensor, info, mask_cpu, samples=5, step=3, unnormalize=True, path_unnorm=path_unnorm)\n",
    "plt.suptitle(\"Ground Truth vs First Timestep Input vs Prediction\", fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 64, 64]) torch.Size([3, 24, 64, 64]) torch.Size([1, 64, 64])\n",
      "torch.Size([3, 12, 2, 64, 64])\n",
      "torch.Size([3, 12, 2, 64, 64])\n",
      "Overall RMSE: 2.354\n",
      "RMSE per variable and time step: tensor([[0.4675, 0.8796, 0.6094, 1.0897, 1.9756, 2.6577, 2.0941, 1.7199, 1.7108,\n",
      "         1.3281, 1.0398, 1.1285],\n",
      "        [1.5686, 3.3839, 9.9891, 5.7674, 5.1942, 1.4577, 9.7733, 2.4632, 2.6650,\n",
      "         3.3576, 5.9067, 6.3296]])\n",
      "Metrics: {'rmse': {'per_var_time': tensor([[0.4675, 0.8796, 0.6094, 1.0897, 1.9756, 2.6577, 2.0941, 1.7199, 1.7108,\n",
      "         1.3281, 1.0398, 1.1285],\n",
      "        [1.5686, 3.3839, 9.9891, 5.7674, 5.1942, 1.4577, 9.7733, 2.4632, 2.6650,\n",
      "         3.3576, 5.9067, 6.3296]]), 'overall': tensor(2.3537)}, 'mae': {'per_var_time': tensor([[ 0.6297,  1.2771,  0.8202,  1.7304,  3.3362,  4.5289,  3.5767,  2.9183,\n",
      "          2.8928,  2.2204,  1.7019,  1.8055],\n",
      "        [ 2.2078,  5.2255, 16.9514,  9.0744,  8.6560,  1.8788, 16.4512,  3.9273,\n",
      "          4.0796,  5.5121, 10.0151, 10.5642]]), 'overall': tensor(1.6942)}, 'ssim': {'per_var_time': array([[0.70304918, 0.66430301, 0.58941886, 0.45060696, 0.27630814,\n",
      "        0.07217047, 0.17157951, 0.17540944, 0.1601019 , 0.2310505 ,\n",
      "        0.24113188, 0.16857393],\n",
      "       [0.35643428, 0.29254716, 0.2608703 , 0.18261969, 0.26021063,\n",
      "        0.31338238, 0.21051122, 0.33748563, 0.33161327, 0.32007915,\n",
      "        0.29930647, 0.2899918 ]])}, 'wasserstein': {'per_var_time': array([[0.04798608, 0.37803302, 0.08084821, 0.57671954, 1.1120751 ,\n",
      "        1.50964223, 1.19222505, 0.97277418, 0.96428261, 0.73991624,\n",
      "        0.56592607, 0.59851772],\n",
      "       [0.51646027, 1.69481049, 5.65048163, 3.02479284, 2.88531106,\n",
      "        0.42129015, 5.4809468 , 1.27370013, 1.27499971, 1.83064413,\n",
      "        3.33707132, 3.51069025]])}, 'anomaly_correlation': {'per_var_time': array([[-0.0270448 ,  0.00871646, -0.00976401,  0.0051764 , -0.00975078,\n",
      "         0.00887887, -0.01179848,  0.01582223,  0.00748752,  0.02158979,\n",
      "        -0.00543131,  0.01287291],\n",
      "       [ 0.0020002 ,  0.01192951, -0.00889391, -0.00191415, -0.0008217 ,\n",
      "         0.00843424,  0.02379384, -0.01080139, -0.00784227,  0.00126012,\n",
      "         0.01889354,  0.00753602]])}}\n"
     ]
    }
   ],
   "source": [
    "import metrics\n",
    "importlib.reload(metrics)\n",
    "preds = torch.stack([x_preds[i] for i in range(num_samples)]).squeeze(1)\n",
    "gt = x_star.detach().cpu()\n",
    "gt = gt.repeat(3,1,1,1)\n",
    "print(preds.shape, gt.shape, mask_cpu.shape)\n",
    "rmse_per_var_time, overall_rmse = metrics.calculate_rmse(preds, gt, mask_cpu)\n",
    "metrics_results = metrics.calculate_metrics(preds, gt, mask_cpu)\n",
    "print(f\"Overall RMSE: {overall_rmse:.3f}\")\n",
    "print(f\"RMSE per variable and time step: {rmse_per_var_time}\")\n",
    "print(f\"Metrics: {metrics_results}\")\n",
    "metrics.plot_metric_comparison(metrics_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
